{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/learning_curve.py:22: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas_datareader as pdr\n",
    "import pickle\n",
    "import time\n",
    "import gc\n",
    "\n",
    "from multiprocessing import *\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import *\n",
    "from numba import jit\n",
    "from sklearn.datasets import make_friedman1\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, Imputer\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TRAIN_PATH = './Data/train.csv'\n",
    "DATA_TEST_PATH =  './Data/test.csv'\n",
    "\n",
    "def load_data(train_path = DATA_TRAIN_PATH, test_path = DATA_TEST_PATH):\n",
    "    train = pd.read_csv(train_path, na_values = \"-1\", dtype = np.float64)\n",
    "    train = train.fillna(-1)\n",
    "    test = pd.read_csv(test_path, na_values = \"-1\")\n",
    "    test = test.fillna(-1)\n",
    "    \n",
    "    x_train = train.drop(['target', 'id'], axis = 1)\n",
    "    y_train = train['target']\n",
    "    id_train = train['id'].values\n",
    "    print('Train data shape: ', x_train.shape)\n",
    "    \n",
    "    x_test = test.drop(['id'], axis = 1)\n",
    "    id_test = test['id'].values\n",
    "    print('Test data shape: ', x_test.shape)   \n",
    "    \n",
    "    return x_train, y_train, id_train, x_test, id_test\n",
    "\n",
    "def feature_info(df):\n",
    "    cat_features = df.columns[df.columns.str.endswith('cat')].tolist()\n",
    "    bin_features = df.columns[df.columns.str.endswith('bin')].tolist()\n",
    "    num_features = [feature for feature in df.columns.tolist() \n",
    "                    if feature not in cat_features and feature not in bin_features]\n",
    "    return cat_features, bin_features, num_features\n",
    "\n",
    "def submit(filename, id_test, pred_test):\n",
    "    sub = pd.DataFrame()\n",
    "    sub['id'] = id_test\n",
    "    sub['target'] = pred_test\n",
    "    sub.to_csv(filename, index = False)\n",
    "\n",
    "def gini(y_true, y_prob):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_true = y_true[np.argsort(y_prob)]\n",
    "    ntrue = 0\n",
    "    gini = 0\n",
    "    delta = 0\n",
    "    n = len(y_true)\n",
    "    for i in range(n-1, -1, -1):\n",
    "        y_i = y_true[i]\n",
    "        ntrue += y_i\n",
    "        gini += y_i * delta\n",
    "        delta += 1 - y_i\n",
    "    gini = 1 - 2 * gini / (ntrue * (n - ntrue))\n",
    "    return gini\n",
    "\n",
    "def gini_normalized(y_true, y_pred):\n",
    "    return gini(y_true, y_pred)/gini(y_true, y_true)\n",
    "\n",
    "def gini_xgb(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    gini_score = gini_normalized(labels, preds)\n",
    "    return[('gini', gini_score)]\n",
    "\n",
    "def gini_lgb(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    gini_score = gini_normalized(labels, preds)\n",
    "    return 'gini', gini_score, True    \n",
    "    \n",
    "def add_noise(series, noise_level):\n",
    "    return series*( 1+ noise_level * np.random.randn(len(series)))\n",
    "\n",
    "\n",
    "def target_encoder(trn_series=None, tst_series=None, target=None, \n",
    "                    min_samples_leaf=1, smoothing=1, noise_level=0):\n",
    "    \n",
    "    \"\"\"\n",
    "    Smoothing is computed like in the following paper by Daniele Micci-Barreca\n",
    "    https://kaggle2.blob.core.windows.net/forum-message-attachments/225952/7441/high%20cardinality%20categoricals.pdf\n",
    "    trn_series : training categorical feature as a pd.Series\n",
    "    tst_series : test categorical feature as a pd.Series\n",
    "    target : target data as a pd.Series\n",
    "    min_samples_leaf (int) : minimum samples to take category average into account\n",
    "    smoothing (int) : smoothing effect to balance categorical average vs prior  \n",
    "    \"\"\" \n",
    "        \n",
    "    assert len(trn_series) == len(target)\n",
    "    assert trn_series.name == tst_series.name\n",
    "    temp = pd.concat([trn_series, target], axis=1)\n",
    "    \n",
    "    # Compute target mean \n",
    "    averages = temp.groupby(by=trn_series.name)[target.name].agg([\"mean\", \"count\"])\n",
    "    \n",
    "    # Compute smoothing\n",
    "    smoothing = 1 / (1 + np.exp(-(averages[\"count\"] - min_samples_leaf) / smoothing))\n",
    "    \n",
    "    # Apply average function to all target data\n",
    "    prior = target.mean()\n",
    "    \n",
    "    # The bigger the count the less full_avg is taken into account\n",
    "    averages[target.name] = prior * (1 - smoothing) + averages[\"mean\"] * smoothing\n",
    "    averages.drop([\"mean\", \"count\"], axis=1, inplace=True)\n",
    "    \n",
    "    # Apply averages to trn and tst series\n",
    "    ft_trn_series = pd.merge(\n",
    "        trn_series.to_frame(trn_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on=trn_series.name,how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    \n",
    "    # pd.merge does not keep the index so restore it    \n",
    "    ft_trn_series.index = trn_series.index \n",
    "    \n",
    "    ft_tst_series = pd.merge(\n",
    "        tst_series.to_frame(tst_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on=tst_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    # pd.merge does not keep the index so restore it\n",
    "    ft_tst_series.index = tst_series.index\n",
    "    \n",
    "    return add_noise(ft_trn_series, noise_level), add_noise(ft_tst_series, noise_level)   \n",
    "\n",
    "def rfe_svc(x_train, y_train):\n",
    "    estimator = SVC(kernel='rbf', C=1, verbose = True)    \n",
    "    #rfe = RFE(estimator = estimator, n_features_to_select=5, step = 1, verbose = 1)    \n",
    "    rfe = RFECV(estimator = estimator, step = 1, cv = 5 , verbose = 1)\n",
    "    rfe = rfe.fit(x_train, y_train)    \n",
    "    return rfe.ranking_, rfe.support_\n",
    "\n",
    "def rfe_gb(x_train, y_train):\n",
    "    estimator = ExtraTreesClassifier(n_estimators = 50, max_depth=None, min_samples_split=2, random_state=0, verbose=1)    \n",
    "    estimator = estimator.fit(x_train, y_train)\n",
    "    model = SelectFromModel(estimator, prefit = True)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def transform_df(df_train, df_test, df_label):             \n",
    "    \n",
    "    df_train = pd.DataFrame(df_train)   \n",
    "    df_test = pd.DataFrame(df_test)\n",
    "    \n",
    "    cat_features, bin_features, num_features = feature_info(df_train)\n",
    "    \n",
    "    for i in cat_features:       \n",
    "        imp = Imputer(missing_values = -1, strategy = 'most_frequent', axis = 0, verbose =1, copy = False)       \n",
    "        df_train[i] = imp.fit_transform(df_train[i].reshape(-1,1))        \n",
    "        df_test[i] = imp.fit_transform(df_test[i].reshape(-1,1))        \n",
    "        \n",
    "        df_train[i], df_test[i] = target_encoder(df_train[i], df_test[i], df_label, \n",
    "                                                min_samples_leaf = 100, smoothing = 10,\n",
    "                                               noise_level = 0.01)    \n",
    "    \n",
    "    df_train['ps_car_13_x_ps_reg_03'] = df_train['ps_car_13'] * df_train['ps_reg_03']    \n",
    "    df_train['ps_car_02_cat_x_ps_reg_01'] = df_train['ps_car_02_cat'] * df_train['ps_reg_01']\n",
    "    df_train['ps_car_04_cat_x_ps_reg_01'] = df_train['ps_car_04_cat'] * df_train['ps_reg_01']\n",
    "        \n",
    "    df_test['ps_car_13_x_ps_reg_03'] = df_test['ps_car_13'] * df_test['ps_reg_03']\n",
    "    df_test['ps_car_02_cat_x_ps_reg_01'] = df_test['ps_car_02_cat'] * df_test['ps_reg_01']\n",
    "    df_test['ps_car_04_cat_x_ps_reg_01'] = df_test['ps_car_04_cat'] * df_test['ps_reg_01']            \n",
    "    \n",
    "    \n",
    "    print('Train data shape: ', df_train.shape)\n",
    "    print('Test data shape: ', df_test.shape)\n",
    "    \n",
    "    return df_train, df_test   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (595212, 57)\n",
      "Test data shape:  (892816, 57)\n",
      "Train data shape:  (595212, 60)\n",
      "Test data shape:  (892816, 60)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, id_train, x_test, id_test = load_data(train_path = DATA_TRAIN_PATH, test_path = DATA_TEST_PATH)\n",
    "x_train, x_test=transform_df(x_train, x_test, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ranking, support = rfe_svc(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rfe_model = rfe_gb(x_train, y_train)\n",
    "# x_train = pd.DataFrame(rfe_model.transform(x_train))\n",
    "# x_test =  pd.DataFrame(rfe_model.transform(x_test))\n",
    "# print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = 5\n",
    "num_round = 10000\n",
    "early_stopping_rounds = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {}\n",
    "\n",
    "#best parameter\n",
    "lgb_params[0] = {}\n",
    "lgb_params[0]['boosting'] = 'gbdt'\n",
    "lgb_params[0]['learning_rate'] = 0.01\n",
    "lgb_params[0]['max_depth'] = 8\n",
    "lgb_params[0]['max_bin'] = 10\n",
    "lgb_params[0]['feature_fraction'] = 0.8\n",
    "lgb_params[0]['bagging_fraction'] = 0.9\n",
    "lgb_params[0]['bagging_frequency'] = 5\n",
    "lgb_params[0]['min_data'] = 500\n",
    "lgb_params[0]['objective'] = 'binary'\n",
    "lgb_params[0]['metric'] = 'auc'\n",
    "lgb_params[0]['bagging_seed'] = 99\n",
    "\n",
    "lgb_params[1] = {}\n",
    "lgb_params[1]['boosting'] = 'gbdt'\n",
    "lgb_params[1]['learning_rate'] = 0.02\n",
    "lgb_params[1]['max_depth'] = 6\n",
    "lgb_params[1]['max_bin'] = 10\n",
    "lgb_params[1]['feature_fraction'] = 0.8\n",
    "lgb_params[1]['bagging_fraction'] = 0.9\n",
    "lgb_params[1]['bagging_frequency'] = 5\n",
    "lgb_params[1]['min_data'] = 500\n",
    "lgb_params[1]['objective'] = 'binary'\n",
    "lgb_params[1]['metric'] = 'auc'\n",
    "lgb_params[1]['bagging_seed'] = 99\n",
    "\n",
    "lgb_params[2] = {}\n",
    "lgb_params[2]['boosting'] = 'gbdt'\n",
    "lgb_params[2]['learning_rate'] = 0.02\n",
    "lgb_params[2]['max_depth'] = 4\n",
    "lgb_params[2]['num_leaves'] = 0.70 * (2**lgb_params[2]['max_depth'])\n",
    "lgb_params[2]['max_bin'] = 10\n",
    "lgb_params[2]['feature_fraction'] = 0.8\n",
    "lgb_params[2]['bagging_fraction'] = 0.9\n",
    "lgb_params[2]['bagging_frequency'] = 5\n",
    "lgb_params[2]['min_data'] = 500\n",
    "lgb_params[2]['objective'] = 'binary'\n",
    "lgb_params[2]['metric'] = 'auc'\n",
    "lgb_params[2]['bagging_seed'] = 99\n",
    "\n",
    "lgb_params[3] = {}\n",
    "lgb_params[3]['boosting'] = 'gbdt'\n",
    "lgb_params[3]['learning_rate'] = 0.02\n",
    "lgb_params[3]['max_depth'] = 10\n",
    "lgb_params[3]['num_leaves'] = 0.50 * (2**lgb_params[2]['max_depth'])\n",
    "lgb_params[3]['max_bin'] = 10\n",
    "lgb_params[3]['feature_fraction'] = 0.8\n",
    "lgb_params[3]['bagging_fraction'] = 0.9\n",
    "lgb_params[3]['bagging_frequency'] = 5\n",
    "lgb_params[3]['min_data'] = 500\n",
    "lgb_params[3]['objective'] = 'binary'\n",
    "lgb_params[3]['metric'] = 'auc'\n",
    "lgb_params[3]['bagging_seed'] = 99\n",
    "lgb_params[3]['lambda_l2'] = 0.00005\n",
    "\n",
    "lgb_params[4] = {}\n",
    "lgb_params[4]['boosting'] = 'gbdt'\n",
    "lgb_params[4]['learning_rate'] = 0.02\n",
    "lgb_params[4]['max_depth'] = 10\n",
    "lgb_params[4]['num_leaves'] = 0.70 * (2**lgb_params[2]['max_depth'])\n",
    "lgb_params[4]['max_bin'] = 10\n",
    "lgb_params[4]['feature_fraction'] = 0.8\n",
    "lgb_params[4]['bagging_fraction'] = 0.9\n",
    "lgb_params[4]['bagging_frequency'] = 5\n",
    "lgb_params[4]['min_data'] = 500\n",
    "lgb_params[4]['objective'] = 'binary'\n",
    "lgb_params[4]['metric'] = 'auc'\n",
    "lgb_params[4]['bagging_seed'] = 99\n",
    "lgb_params[4]['lambda_l1'] = 0.00001\n",
    "\n",
    "lgb_params[5] = {}\n",
    "lgb_params[5]['boosting'] = 'dart'\n",
    "lgb_params[5]['xgboost_dart_mode'] = True\n",
    "lgb_params[5]['learning_rate'] = 0.02\n",
    "lgb_params[5]['max_depth'] = 6\n",
    "lgb_params[5]['max_bin'] = 10\n",
    "lgb_params[5]['feature_fraction'] = 0.8\n",
    "lgb_params[5]['bagging_fraction'] = 0.9\n",
    "lgb_params[5]['bagging_frequency'] = 10\n",
    "lgb_params[5]['min_data'] = 500\n",
    "lgb_params[5]['objective'] = 'binary'\n",
    "lgb_params[5]['metric'] = 'auc'\n",
    "lgb_params[5]['bagging_seed'] = 99\n",
    "\n",
    "lgb_params[6] = {}\n",
    "lgb_params[6]['boosting'] = 'dart'\n",
    "lgb_params[5]['xgboost_dart_mode'] = True\n",
    "lgb_params[6]['learning_rate'] = 0.02\n",
    "lgb_params[6]['max_depth'] = 10\n",
    "lgb_params[6]['max_bin'] = 10\n",
    "lgb_params[6]['feature_fraction'] = 0.8\n",
    "lgb_params[6]['bagging_fraction'] = 0.9\n",
    "lgb_params[6]['bagging_frequency'] = 10\n",
    "lgb_params[6]['min_data'] = 500\n",
    "lgb_params[6]['objective'] = 'binary'\n",
    "lgb_params[6]['metric'] = 'auc'\n",
    "lgb_params[6]['bagging_seed'] = 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " light gbm kfold: 1  of  5 : \n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.621082\tvalid_0's gini: 0.242169\n",
      "[200]\tvalid_0's auc: 0.622571\tvalid_0's gini: 0.245141\n",
      "[300]\tvalid_0's auc: 0.626138\tvalid_0's gini: 0.252275\n",
      "[400]\tvalid_0's auc: 0.631174\tvalid_0's gini: 0.262347\n",
      "[500]\tvalid_0's auc: 0.633941\tvalid_0's gini: 0.267883\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred = []\n",
    "for k in range(2):       \n",
    "    stratkfold = StratifiedKFold(n_splits=kfold, random_state=None, shuffle = True)\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(stratkfold.split(x_train, y_train)):   \n",
    "        print(' light gbm kfold: {}  of  {} : '.format(i+1, kfold))    \n",
    "        d_train = lgb.Dataset(x_train.iloc[train_index], label = y_train.iloc[train_index]) \n",
    "        d_valid = lgb.Dataset(x_train.iloc[test_index], label = y_train.iloc[test_index]) \n",
    "\n",
    "        model = lgb.train(lgb_params[k], d_train, num_round, d_valid, early_stopping_rounds = early_stopping_rounds, \n",
    "                      feval = gini_lgb, verbose_eval = 100)\n",
    "        y_pred.append(model.predict(x_test, num_iteration=(model.best_iteration)))\n",
    "\n",
    "        print(\"_\"*90 + '\\n')\n",
    "\n",
    "    model.save_model('./Model/lgb_model_'+ str(k) + '.txt')\n",
    "    print(\"*\"*90)\n",
    "    print(\"*\"*90 + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lgb = np.mean(np.array(y_pred), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {}\n",
    "\n",
    "xgb_params[0] = {}\n",
    "xgb_params[0]['eta'] = 0.02 \n",
    "xgb_params[0]['max_depth'] = 6\n",
    "xgb_params[0]['subsample'] = 0.8\n",
    "xgb_params[0]['colsample_bytree'] = 0.8\n",
    "xgb_params[0]['objective'] = 'binary:logistic'\n",
    "xgb_params[0]['eval_metric'] = 'auc'\n",
    "xgb_params[0]['seed'] = 99\n",
    "xgb_params[0]['silent'] = True\n",
    "\n",
    "xgb_params[1] = {}\n",
    "xgb_params[1]['eta'] = 0.02 \n",
    "xgb_params[1]['gamma'] = 0.0005\n",
    "xgb_params[1]['max_depth'] = 5\n",
    "xgb_params[1]['subsample'] = 0.8\n",
    "xgb_params[1]['colsample_bytree'] = 0.8\n",
    "xgb_params[1]['objective'] = 'binary:logistic'\n",
    "xgb_params[1]['eval_metric'] = 'auc'\n",
    "xgb_params[1]['seed'] = 99\n",
    "xgb_params[1]['silent'] = True\n",
    "\n",
    "xgb_params[2] = {}\n",
    "xgb_params[2]['eta'] = 0.05 \n",
    "xgb_params[1]['alpha'] = 0.0005\n",
    "xgb_params[2]['max_depth'] = 10\n",
    "xgb_params[2]['subsample'] = 0.8\n",
    "xgb_params[2]['colsample_bytree'] = 0.8\n",
    "xgb_params[2]['objective'] = 'binary:logistic'\n",
    "xgb_params[2]['eval_metric'] = 'auc'\n",
    "xgb_params[2]['seed'] = 99\n",
    "xgb_params[2]['silent'] = True\n",
    "\n",
    "xgb_params[3] = {}\n",
    "xgb_params[3]['eta'] = 0.05\n",
    "xgb_params[1]['alpha'] = 0.0002\n",
    "xgb_params[3]['max_depth'] = 6\n",
    "xgb_params[3]['subsample'] = 0.8\n",
    "xgb_params[3]['colsample_bytree'] = 0.8\n",
    "xgb_params[3]['objective'] = 'binary:logistic'\n",
    "xgb_params[3]['eval_metric'] = 'auc'\n",
    "xgb_params[3]['seed'] = 99\n",
    "xgb_params[3]['silent'] = True\n",
    "\n",
    "# xgb_params[4] = {}\n",
    "# xgb_params[4]['eta'] = 0.05 \n",
    "# xgb_params[4]['max_depth'] = 10\n",
    "# xgb_params[4]['subsample'] = 0.8\n",
    "# xgb_params[4]['colsample_bytree'] = 0.8\n",
    "# xgb_params[4]['objective'] = 'binary:logistic'\n",
    "# xgb_params[4]['eval_metric'] = 'auc'\n",
    "# xgb_params[4]['seed'] = 99\n",
    "# xgb_params[4]['silent'] = True\n",
    "\n",
    "# xgb_params[5] = {}\n",
    "# xgb_params[5]['eta'] = 0.05 \n",
    "# xgb_params[5]['max_depth'] = 10\n",
    "# xgb_params[5]['subsample'] = 0.8\n",
    "# xgb_params[5]['colsample_bytree'] = 0.8\n",
    "# xgb_params[5]['objective'] = 'binary:logistic'\n",
    "# xgb_params[5]['eval_metric'] = 'auc'\n",
    "# xgb_params[5]['seed'] = 99\n",
    "# xgb_params[5]['silent'] = True\n",
    "\n",
    "# xgb_params[6] = {}\n",
    "# xgb_params[6]['eta'] = 0.05 \n",
    "# xgb_params[6]['max_depth'] = 10\n",
    "# xgb_params[6]['subsample'] = 0.8\n",
    "# xgb_params[6]['colsample_bytree'] = 0.8\n",
    "# xgb_params[6]['objective'] = 'binary:logistic'\n",
    "# xgb_params[6]['eval_metric'] = 'auc'\n",
    "# xgb_params[6]['seed'] = 99\n",
    "# xgb_params[6]['silent'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "\n",
    "for k in range(2):\n",
    "    stratkfold = StratifiedKFold(n_splits=kfold, random_state=None, shuffle = True)\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(stratkfold.split(x_train, y_train)):\n",
    "        print(' xgb kfold: {}  of  {} : '.format(i+1, kfold))    \n",
    "        d_train = xgb.DMatrix(x_train.iloc[train_index], y_train.iloc[train_index]) \n",
    "        d_valid = xgb.DMatrix(x_train.iloc[test_index], y_train.iloc[test_index]) \n",
    "        watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "\n",
    "        model = xgb.train(xgb_params[k], d_train, num_round, watchlist, early_stopping_rounds = early_stopping_rounds, \n",
    "                      feval = gini_xgb, maximize = True, verbose_eval = 50)\n",
    "\n",
    "        y_pred.append(model.predict(xgb.DMatrix(x_test), ntree_limit=model.best_ntree_limit))\n",
    "        print(\"_\"*90 + '\\n')\n",
    "        \n",
    "    pickle.dump(model, open(\"./Model/xgb_model_\" + str(k) + \".pickle.dat\", \"wb\")) \n",
    "    print(\"*\"*90)\n",
    "    print(\"*\"*90 + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb = np.mean(np.array(y_pred), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_final = np.mean(np.array([y_pred_lgb, y_pred_xgb]), axis=0)\n",
    "submit('gb_mean.csv', id_test, y_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
